%!TEX root=report.tex

\subsection{OLS with autocorrelated residuals}

In OLS it is assumed that the residuals between different observations are uncorrelated. However since our data is a time series this assumption does most likely not hold. This can also be confirmed with the Durbin-Watson test statistic \cite[p.~173]{autocorrelation-kousgaard}. This test statistic is calculated using
\begin{equation}
d = \frac{\sum_{i=2}^n \left( \hat{\epsilon}_i - \hat{\epsilon}_{i-1} \right)^2}{ \sum_{i=1}^n\hat{\epsilon}_i^2 }
\end{equation}

which lies between 0 and 4. If $d$ is close to 0 the residuals $\hat{\epsilon}_i$ and $\hat{\epsilon}_{i-1}$ are correlated positively, if close to 4 the residuals are negatively correlated. The purpose of this method is to reduce the correlation between the residuals, the Durbin-Watson test statistic should then become 2.

When the residuals are correlated, one gets bad estimation of the variance of the residuals $\hat{\sigma}_\epsilon^2$. This in turn leads to bad interference statistics, such as misleading p-values.

To correct for the correlated residuals, one can use a weighted least squares (WLS) regression. This uses a $\Sigma$ matrix there will correct for the correlated residuals
\begin{equation}
\min_{\beta, \rho}\ (Y-X\beta)^T \Sigma^{-1}(Y-X\beta),
\label{eq:theory-olsar-min}
\end{equation}

where $ \Sigma^{-1}$ is given as
\begin{equation}
\Sigma^{-1}  = \begin{bmatrix}
1         & -\rho         & 0               & \cdots & 0              & 0         \\
-\rho   & 1+\rho^2 & -\rho         & \cdots & 0               & 0         \\
0         & -\rho         & 1+\rho^2 & \cdots &0                & 0         \\
\vdots & \vdots      & \vdots       & \ddots & \vdots      & \vdots \\
0         & 0               &0                & \cdots & 1+\rho^2 & -\rho    \\
0         & 0               &0                & \cdots &-\rho          & 1
\end{bmatrix}
\end{equation}

The optimization problem \eqref{eq:theory-olsar-min} is nonlinear and there is no closed form solution to this problem. However when keeping $\rho$ constant the $\beta$ parameters can be estimated using Weighted Least Squared, which is similar to OLS but with a constant $\Sigma$ matrix and have the solution \cite[p.~38]{time-series-analysis}
\begin{equation}
\hat{\beta} = (X^T \Sigma^{-1} X)^{-1} X^T \Sigma^{-1} Y.
\end{equation}

This should then be rewritten using SVD, to account for a near singular $X^T \Sigma^{-1} X$ matrix.

Similarly when $\beta$ is kept constant, $\rho$ can be estimated with  \cite[p.~178]{autocorrelation-kousgaard}
\begin{equation}
\hat{\rho} = \frac{ \sum_{i=2}^n \hat{\epsilon_i}\hat{\epsilon}_{i-1} }{ \sum_{i=2}^{n-1} \hat{\epsilon_i}^2 }.
\label{eq:theory-olsar-rho}
\end{equation}

A practical way of solving the problem with respect to both $\beta$ and $\rho$, looks as follows:
\begin{enumerate}
\item initialize by letting $\rho=0$
\item Iterate: \begin{enumerate}
	\item Keep $\hat{\rho}$ constant and estimate $\beta$ using as a WLS problem.
	
	\item Keep $\hat{\beta}$ constant and estimate $\rho$ using \eqref{eq:theory-olsar-rho}.
	
	\item Repeat until convergence of $\rho$ or until some predetermined upper iteration boundary is met.
\end{enumerate}
\end{enumerate}
